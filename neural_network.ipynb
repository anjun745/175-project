{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fb1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f99c44",
   "metadata": {},
   "source": [
    "### No extra weight on buy/sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 0.7021 — Val Acc: 0.7541\n",
      "Epoch 2/10 — Train Loss: 0.6880 — Val Acc: 0.7551\n",
      "Epoch 3/10 — Train Loss: 0.6829 — Val Acc: 0.7567\n",
      "Epoch 4/10 — Train Loss: 0.6772 — Val Acc: 0.7583\n",
      "Epoch 5/10 — Train Loss: 0.6728 — Val Acc: 0.7589\n",
      "Epoch 6/10 — Train Loss: 0.6669 — Val Acc: 0.7597\n",
      "Epoch 7/10 — Train Loss: 0.6600 — Val Acc: 0.7608\n",
      "Epoch 8/10 — Train Loss: 0.6529 — Val Acc: 0.7626\n",
      "Epoch 9/10 — Train Loss: 0.6448 — Val Acc: 0.7651\n",
      "Epoch 10/10 — Train Loss: 0.6372 — Val Acc: 0.7661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# load data and preprocess\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_7']) # no label_7 here\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# features / target\n",
    "X = df.drop(columns=['label_3']).values\n",
    "y = LabelEncoder().fit_transform(df['label_3'])\n",
    "\n",
    "# scale numerics\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "# the actual model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    # training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           StandardScaler().fit(df.drop(columns=['label_3'])),\n",
    "    'label_encoder':    LabelEncoder().fit(df['label_3']),\n",
    "    'stock_encoder':    LabelEncoder().fit(df['stock_id'])\n",
    "}, \"stock_label3_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ebd860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 0.8398 — Val Acc: 0.6693\n",
      "Epoch 2/10 — Train Loss: 0.8261 — Val Acc: 0.6709\n",
      "Epoch 3/10 — Train Loss: 0.8203 — Val Acc: 0.6717\n",
      "Epoch 4/10 — Train Loss: 0.8140 — Val Acc: 0.6739\n",
      "Epoch 5/10 — Train Loss: 0.8063 — Val Acc: 0.6744\n",
      "Epoch 6/10 — Train Loss: 0.7995 — Val Acc: 0.6779\n",
      "Epoch 7/10 — Train Loss: 0.7923 — Val Acc: 0.6823\n",
      "Epoch 8/10 — Train Loss: 0.7839 — Val Acc: 0.6814\n",
      "Epoch 9/10 — Train Loss: 0.7756 — Val Acc: 0.6830\n",
      "Epoch 10/10 — Train Loss: 0.7684 — Val Acc: 0.6856\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_3'])  # different label here\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label_7']).values\n",
    "y = LabelEncoder().fit_transform(df['label_7'])\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "# no changes to the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           scaler,\n",
    "    'label_encoder_7':  LabelEncoder().fit(df['label_7']),\n",
    "    'stock_encoder':    LabelEncoder().fit(df['stock_id'])\n",
    "}, \"stock_label7_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143ccb1",
   "metadata": {},
   "source": [
    "As we can see hold takes a heavy preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7c6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10668208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label_3\n",
       " hold    85037\n",
       " buy     14993\n",
       " sell    12821\n",
       " Name: count, dtype: int64,\n",
       " label_7\n",
       " hold    75290\n",
       " buy     20808\n",
       " sell    16753\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_3'].value_counts(), df['label_7'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 1.0679 — Val Acc: 0.4503\n",
      "Epoch 2/10 — Train Loss: 1.0575 — Val Acc: 0.5133\n",
      "Epoch 3/10 — Train Loss: 1.0494 — Val Acc: 0.5351\n",
      "Epoch 4/10 — Train Loss: 1.0401 — Val Acc: 0.5559\n",
      "Epoch 5/10 — Train Loss: 1.0297 — Val Acc: 0.4721\n",
      "Epoch 6/10 — Train Loss: 1.0191 — Val Acc: 0.4916\n",
      "Epoch 7/10 — Train Loss: 1.0082 — Val Acc: 0.5233\n",
      "Epoch 8/10 — Train Loss: 0.9966 — Val Acc: 0.5201\n",
      "Epoch 9/10 — Train Loss: 0.9857 — Val Acc: 0.5034\n",
      "Epoch 10/10 — Train Loss: 0.9759 — Val Acc: 0.5058\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_3'])\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label_7']).values\n",
    "y = LabelEncoder().fit_transform(df['label_7'])\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# change weights\n",
    "counts = Counter(y_train)\n",
    "total  = len(y_train)\n",
    "num_classes = len(counts)\n",
    "weights = [ total/(num_classes * counts[i]) for i in range(num_classes) ]\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "# move weights onto the same device as model, if using GPU\n",
    "class_weights = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           scaler,\n",
    "    'label_encoder_7':  LabelEncoder().fit(df['label_7']),\n",
    "    'stock_encoder':    LabelEncoder().fit(df['stock_id'])\n",
    "}, \"stock_label7_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 1.0607 — Val Acc: 0.6052\n",
      "Epoch 2/10 — Train Loss: 1.0457 — Val Acc: 0.4986\n",
      "Epoch 3/10 — Train Loss: 1.0357 — Val Acc: 0.5421\n",
      "Epoch 4/10 — Train Loss: 1.0257 — Val Acc: 0.5551\n",
      "Epoch 5/10 — Train Loss: 1.0134 — Val Acc: 0.5444\n",
      "Epoch 6/10 — Train Loss: 0.9999 — Val Acc: 0.4964\n",
      "Epoch 7/10 — Train Loss: 0.9865 — Val Acc: 0.5797\n",
      "Epoch 8/10 — Train Loss: 0.9729 — Val Acc: 0.5645\n",
      "Epoch 9/10 — Train Loss: 0.9582 — Val Acc: 0.5445\n",
      "Epoch 10/10 — Train Loss: 0.9430 — Val Acc: 0.5782\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_7'])\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label_3']).values\n",
    "y = LabelEncoder().fit_transform(df['label_3'])\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# same addition as before\n",
    "counts = Counter(y_train)\n",
    "total  = len(y_train)\n",
    "num_classes = len(counts)\n",
    "weights = [ total/(num_classes * counts[i]) for i in range(num_classes) ]\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "# move to GPU if available later\n",
    "\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "class_weights = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           scaler,\n",
    "    'label_encoder_3':  LabelEncoder().fit(df['label_3']),\n",
    "    'stock_encoder':    LabelEncoder().fit(df['stock_id'])\n",
    "}, \"stock_label3_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63edcd40-0bcc-4379-b91c-3e786ff56836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 1.0671 — Val Acc: 0.4179\n",
      "Epoch 2/10 — Train Loss: 1.0511 — Val Acc: 0.4407\n",
      "Epoch 3/10 — Train Loss: 1.0425 — Val Acc: 0.4341\n",
      "Epoch 4/10 — Train Loss: 1.0352 — Val Acc: 0.4449\n",
      "Epoch 5/10 — Train Loss: 1.0265 — Val Acc: 0.4520\n",
      "Epoch 6/10 — Train Loss: 1.0183 — Val Acc: 0.4591\n",
      "Epoch 7/10 — Train Loss: 1.0079 — Val Acc: 0.4639\n",
      "Epoch 8/10 — Train Loss: 0.9993 — Val Acc: 0.4709\n",
      "Epoch 9/10 — Train Loss: 0.9900 — Val Acc: 0.4824\n",
      "Epoch 10/10 — Train Loss: 0.9788 — Val Acc: 0.4806\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\"\"\"Random Sampling for Equal Amounts of Buy/Hold/Sell\"\"\"\n",
    "# load data and preprocess\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_7']) # no label_7 here\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "buy_df = df[df['label_3'] == 'buy']\n",
    "hold_df = df[df['label_3'] == 'hold']\n",
    "sell_df = df[df['label_3'] == 'sell']\n",
    "\n",
    "min_size = min(len(buy_df), len(hold_df), len(sell_df))\n",
    "\n",
    "buy_bal = resample(buy_df, replace=False, n_samples=min_size, random_state=42)\n",
    "hold_bal = resample(hold_df, replace=False, n_samples=min_size, random_state=42)\n",
    "sell_bal = resample(sell_df, replace=False, n_samples=min_size, random_state=42)\n",
    "\n",
    "train_df = pd.concat([buy_bal, hold_bal, sell_bal]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = train_df.drop(columns=['label_3']).values\n",
    "y = LabelEncoder().fit_transform(train_df['label_3'])\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "# the actual model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    # training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           StandardScaler().fit(train_df.drop(columns=['label_3'])),\n",
    "    'label_encoder':    LabelEncoder().fit(train_df['label_3']),\n",
    "    'stock_encoder':    LabelEncoder().fit(train_df['stock_id'])\n",
    "}, \"stock_label3_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01aa7fbd-03d8-4716-8ebc-9645b82b91d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 1.0748 — Val Acc: 0.4221\n",
      "Epoch 2/10 — Train Loss: 1.0613 — Val Acc: 0.4272\n",
      "Epoch 3/10 — Train Loss: 1.0545 — Val Acc: 0.4422\n",
      "Epoch 4/10 — Train Loss: 1.0475 — Val Acc: 0.4354\n",
      "Epoch 5/10 — Train Loss: 1.0412 — Val Acc: 0.4477\n",
      "Epoch 6/10 — Train Loss: 1.0348 — Val Acc: 0.4377\n",
      "Epoch 7/10 — Train Loss: 1.0269 — Val Acc: 0.4605\n",
      "Epoch 8/10 — Train Loss: 1.0172 — Val Acc: 0.4565\n",
      "Epoch 9/10 — Train Loss: 1.0101 — Val Acc: 0.4674\n",
      "Epoch 10/10 — Train Loss: 0.9994 — Val Acc: 0.4635\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Sampling for Equal Amounts of Buy/Hold/Sell for label 7\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# load data and preprocess\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_3']) # no label_3 here\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "buy_df = df[df['label_7'] == 'buy']\n",
    "hold_df = df[df['label_7'] == 'hold']\n",
    "sell_df = df[df['label_7'] == 'sell']\n",
    "\n",
    "min_size = min(len(buy_df), len(hold_df), len(sell_df))\n",
    "\n",
    "buy_bal = resample(buy_df, replace=False, n_samples=min_size, random_state=42)\n",
    "hold_bal = resample(hold_df, replace=False, n_samples=min_size, random_state=42)\n",
    "sell_bal = resample(sell_df, replace=False, n_samples=min_size, random_state=42)\n",
    "\n",
    "train_df = pd.concat([buy_bal, hold_bal, sell_bal]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = train_df.drop(columns=['label_7']).values\n",
    "y = LabelEncoder().fit_transform(train_df['label_7'])\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "# the actual model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    # training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           StandardScaler().fit(train_df.drop(columns=['label_7'])),\n",
    "    'label_encoder':    LabelEncoder().fit(train_df['label_7']),\n",
    "    'stock_encoder':    LabelEncoder().fit(train_df['stock_id'])\n",
    "}, \"stock_label7_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92adb85b-32e8-479a-940e-d1ab7d317e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 0.7021 — Val Acc: 0.7541\n",
      "Epoch 2/10 — Train Loss: 0.6878 — Val Acc: 0.7554\n",
      "Epoch 3/10 — Train Loss: 0.6818 — Val Acc: 0.7562\n",
      "Epoch 4/10 — Train Loss: 0.6754 — Val Acc: 0.7577\n",
      "Epoch 5/10 — Train Loss: 0.6688 — Val Acc: 0.7593\n",
      "Epoch 6/10 — Train Loss: 0.6611 — Val Acc: 0.7593\n",
      "Epoch 7/10 — Train Loss: 0.6530 — Val Acc: 0.7612\n",
      "Epoch 8/10 — Train Loss: 0.6451 — Val Acc: 0.7653\n",
      "Epoch 9/10 — Train Loss: 0.6367 — Val Acc: 0.7659\n",
      "Epoch 10/10 — Train Loss: 0.6295 — Val Acc: 0.7691\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\"\"\"Dropping sentiment column for label_3\"\"\"\n",
    "# load data and preprocess\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_7']) # no label_7 here\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock','sentiment'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label_3']).values\n",
    "y = LabelEncoder().fit_transform(df['label_3'])\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "# the actual model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    # training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           StandardScaler().fit(df.drop(columns=['label_3'])),\n",
    "    'label_encoder':    LabelEncoder().fit(df['label_3']),\n",
    "    'stock_encoder':    LabelEncoder().fit(df['stock_id'])\n",
    "}, \"stock_label3_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e655b1ca-06c3-4593-bb6f-da76afda4386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 0.8375 — Val Acc: 0.6680\n",
      "Epoch 2/10 — Train Loss: 0.8257 — Val Acc: 0.6702\n",
      "Epoch 3/10 — Train Loss: 0.8199 — Val Acc: 0.6727\n",
      "Epoch 4/10 — Train Loss: 0.8134 — Val Acc: 0.6721\n",
      "Epoch 5/10 — Train Loss: 0.8064 — Val Acc: 0.6761\n",
      "Epoch 6/10 — Train Loss: 0.7992 — Val Acc: 0.6774\n",
      "Epoch 7/10 — Train Loss: 0.7910 — Val Acc: 0.6811\n",
      "Epoch 8/10 — Train Loss: 0.7837 — Val Acc: 0.6812\n",
      "Epoch 9/10 — Train Loss: 0.7758 — Val Acc: 0.6812\n",
      "Epoch 10/10 — Train Loss: 0.7663 — Val Acc: 0.6861\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\"\"\"Dropping sentiment column for label_7\"\"\"\n",
    "# load data and preprocess\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df = df.drop(columns=['date', 'title', 'label_3']) # no label_3 here\n",
    "df['stock_id'] = LabelEncoder().fit_transform(df['stock'])\n",
    "df = df.drop(columns=['stock','sentiment'])\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label_7']).values\n",
    "y = LabelEncoder().fit_transform(df['label_7'])\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(StockDataset(X_train, y_train), batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(StockDataset(X_val,   y_val),   batch_size)\n",
    "\n",
    "# the actual model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(in_dim=X_train.shape[1], hid_dim=128, num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    # training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model(Xb)\n",
    "        loss  = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            correct += (model(Xb).argmax(1) == yb).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{epochs} — Train Loss: {train_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler':           StandardScaler().fit(df.drop(columns=['label_7'])),\n",
    "    'label_encoder':    LabelEncoder().fit(df['label_7']),\n",
    "    'stock_encoder':    LabelEncoder().fit(df['stock_id'])\n",
    "}, \"stock_label7_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7275da3-67d9-4a45-8579-310d973c3803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
